{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Kaggle Challenge - MVA 2024-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team : ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lilian Say : lilian.say@ens-paris-saclay.fr\n",
    "\n",
    "Benjamin Deporte : benjamin.deporte@ens-paris-saclay.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to repo : https://github.com/BenjaminDeporte/MVA_Kernel_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Codage des Kernels 'string'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous avons codé deux Kernels 'string':\n",
    "- le kernel Spectrum\n",
    "- le kernel Mismatch\n",
    "\n",
    "Nous reproduisons dans ce notebook les deux classes, dont la version à jour figure dans le fichier kernels.py du repo\n",
    "\n",
    "Chaque classe contient deux méthodes :\n",
    "- k_value(x1,x2) pour calculer $K(x_1,x_2)$ où $x_1,x_2$ sont deux strings\n",
    "- k_matrix(xs, ys) pour calculer la matrice de Gram $K(x_i,y_j)$\n",
    "\n",
    "Le fichier kernels.py contient également quelques tests unitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSpectrum():\n",
    "    \n",
    "    dna_alphabet = ['A','G','C','T']\n",
    "    \n",
    "    def __init__(self,k=None):\n",
    "        # default value for k\n",
    "        if k is None:\n",
    "            self.k=3\n",
    "        else:\n",
    "            self.k=k\n",
    "        # create list of k-uplets for faster computation\n",
    "        # product create an iterator of tuples of cartesian products\n",
    "        iter_tuples = product(self.dna_alphabet, repeat=self.k)\n",
    "        # change from tuples of k characters to strings\n",
    "        self.all_kuplets = [ ''.join(t) for t in iter_tuples]\n",
    "        \n",
    "    def k_value(self,x1,x2):\n",
    "        \"\"\"Compute K(x,y)\n",
    "\n",
    "        Args:\n",
    "            x1 (_type_): string, or array of one string\n",
    "            x2 (_type_): string, or array of one string\n",
    "\n",
    "        Raises:\n",
    "            NameError: if not string in inputs\n",
    "\n",
    "        Returns:\n",
    "            _type_: kernel_spectrum(x1,x2)\n",
    "        \"\"\"\n",
    "        # type check and recast\n",
    "        if isinstance(x1, np.ndarray):\n",
    "            x1 = x1.squeeze()\n",
    "            x1 = x1[0]\n",
    "        if isinstance(x2, np.ndarray):\n",
    "            x2 = x2.squeeze()\n",
    "            x2 = x2[0]\n",
    "        if isinstance(x1, str) is False or isinstance(x2, str) is False:\n",
    "            raise NameError('Can not compute a kernel on data not string')\n",
    "            \n",
    "        # list all k-uplets in x1\n",
    "        x1_kuplets = [ x1[i:i+self.k] for i in range(len(x1)-self.k+1) ]\n",
    "        c1 = Counter()\n",
    "        for uplet in x1_kuplets:\n",
    "            c1[uplet] += 1\n",
    "        # list all k-uplets in x2\n",
    "        x2_kuplets = [ x2[i:i+self.k] for i in range(len(x2)-self.k+1) ]\n",
    "        c2 = Counter()\n",
    "        for uplet in x2_kuplets:\n",
    "            c2[uplet] += 1\n",
    "        # compute kernel value\n",
    "        kernel = 0\n",
    "        for uplet, occurences_in_x1 in c1.items():\n",
    "            occurences_in_x2 = c2.get(uplet, 0)\n",
    "            kernel += occurences_in_x1 * occurences_in_x2\n",
    "            \n",
    "        return kernel\n",
    "    \n",
    "    def k_matrix(self, xs, ys):\n",
    "        \"\"\"compute and return Gram matrix K(x_i, y_j) \n",
    "        for i in range(xs), j in range(xs)\n",
    "\n",
    "        Args:\n",
    "            xs (_type_): array of strings\n",
    "            ys (_type_): array of strings\n",
    "        \"\"\"\n",
    "        x_data = xs\n",
    "        y_data = ys\n",
    "        if isinstance(xs, list) is True:\n",
    "            x_data = np.array(xs)\n",
    "        if isinstance(ys, list) is True:\n",
    "            y_data = np.array(ys)\n",
    "                \n",
    "        if isinstance(x_data, np.ndarray) is False or isinstance(y_data, np.ndarray) is False:\n",
    "            raise NameError('can not compute design matrix - input is not an array')\n",
    "        \n",
    "        nx = x_data.shape[0]\n",
    "        ny = y_data.shape[0]\n",
    "        gram = np.zeros((nx, ny))\n",
    "        \n",
    "        for i in range(nx):\n",
    "            x_i = x_data[i]\n",
    "            for j in range(ny):\n",
    "                y_j = y_data[j]\n",
    "                gram[i,j] = self.k_value(x_i, y_j)\n",
    "    \n",
    "        return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMismatch():\n",
    "    \n",
    "    dna_alphabet = ['A','G','C','T']\n",
    "    \n",
    "    def __init__(self,k=None):\n",
    "        # default value for k\n",
    "        if k is None:\n",
    "            self.k=3\n",
    "        else:\n",
    "            self.k=k\n",
    "        # create list of k-uplets for faster computation\n",
    "        # product create an iterator of tuples of cartesian products\n",
    "        iter_tuples = product(self.dna_alphabet, repeat=self.k)\n",
    "        # change from tuples of k characters to strings\n",
    "        self.all_kuplets = [ ''.join(t) for t in iter_tuples]\n",
    "        \n",
    "    def _mismatches(self, kuplet, mismatches=1):\n",
    "        \"\"\"Compute all possible mismatches of k-uplet, with at most m mismatches\n",
    "\n",
    "        Args:\n",
    "            kuplet (string): input k-uplet\n",
    "            m (int, optional): maximum number of allowed mismatches. Defaults to 1.\n",
    "        \"\"\"\n",
    "        mismatches_kuplets = []\n",
    "        \n",
    "        for alphabet_kuplet in self.all_kuplets:\n",
    "            nb_mismatches = np.sum([kuplet[i] != alphabet_kuplet[i] for i in range(self.k)])\n",
    "            if nb_mismatches <= mismatches:\n",
    "                mismatches_kuplets.append(alphabet_kuplet)\n",
    "        \n",
    "        return mismatches_kuplets\n",
    "        \n",
    "    def k_value(self,x1,x2, mismatches=1, verbose=False):\n",
    "        \"\"\"Compute K(x,y)\n",
    "\n",
    "        Args:\n",
    "            x1 (_type_): string, or array of one string\n",
    "            x2 (_type_): string, or array of one string\n",
    "\n",
    "        Raises:\n",
    "            NameError: if not string in inputs\n",
    "\n",
    "        Returns:\n",
    "            _type_: kernel_spectrum(x1,x2)\n",
    "        \"\"\"\n",
    "        # type check and recast\n",
    "        if isinstance(x1, np.ndarray):\n",
    "            x1 = x1.squeeze()\n",
    "            x1 = x1[0]\n",
    "        if isinstance(x2, np.ndarray):\n",
    "            x2 = x2.squeeze()\n",
    "            x2 = x2[0]\n",
    "        if isinstance(x1, str) is False or isinstance(x2, str) is False:\n",
    "            raise NameError('Can not compute a kernel on data not string')\n",
    "            \n",
    "        # list all k-uplets in x1\n",
    "        x1_kuplets = [ x1[i:i+self.k] for i in range(len(x1)-self.k+1) ]\n",
    "        # compute dictionnary of unique kuplets in x1 with number of occurences\n",
    "        c1 = Counter()\n",
    "        for uplet in x1_kuplets:\n",
    "            c1[uplet] += 1\n",
    "            \n",
    "        # list all k-uplets in x2\n",
    "        x2_kuplets = [ x2[i:i+self.k] for i in range(len(x2)-self.k+1) ]\n",
    "        # compute dictionnary of unique kuplets in x2 with number of occurences\n",
    "        c2 = Counter()\n",
    "        for uplet in x2_kuplets:\n",
    "            c2[uplet] += 1\n",
    "        \n",
    "        kernel = 0\n",
    "        # loop over unique kuplets in x1\n",
    "        for uplet, occurences in c1.items():\n",
    "            # what are all possible mismatches of this kuplet\n",
    "            mismatches_kuplet = self._mismatches(uplet, mismatches=mismatches)\n",
    "            for mismatch in mismatches_kuplet:\n",
    "                # how many times does this mismatched kuplet appear in x2\n",
    "                occurences_in_x2 = c2.get(mismatch, 0)\n",
    "                kernel += occurences * occurences_in_x2\n",
    "                if occurences_in_x2 > 0 and verbose is True:\n",
    "                    print(f\"uplet in x1 = {uplet}, mismatch in x1 occuring in x2 = {mismatch}, number of occurences_in_x2 = {occurences_in_x2}\")\n",
    "                \n",
    "        return kernel\n",
    "    \n",
    "    def k_matrix(self, xs, ys):\n",
    "        \"\"\"compute and return Gram matrix K(x_i, y_j) \n",
    "        for i in range(xs), j in range(xs)\n",
    "\n",
    "        Args:\n",
    "            xs (_type_): array of strings\n",
    "            ys (_type_): array of strings\n",
    "        \"\"\"\n",
    "        x_data = xs\n",
    "        y_data = ys\n",
    "        if isinstance(xs, list) is True:\n",
    "            x_data = np.array(xs)\n",
    "        if isinstance(ys, list) is True:\n",
    "            y_data = np.array(ys)\n",
    "                \n",
    "        if isinstance(x_data, np.ndarray) is False or isinstance(y_data, np.ndarray) is False:\n",
    "            raise NameError('can not compute design matrix - input is not an array')\n",
    "        \n",
    "        nx = x_data.shape[0]\n",
    "        ny = y_data.shape[0]\n",
    "        gram = np.zeros((nx, ny))\n",
    "        \n",
    "        for i in range(nx):\n",
    "            x_i = x_data[i]\n",
    "            for j in range(ny):\n",
    "                y_j = y_data[j]\n",
    "                gram[i,j] = self.k_value(x_i, y_j)\n",
    "    \n",
    "        return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Classifieur SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons réutilisé le code du HomeWork 2. Nos deux classes KernelSVC figurent dans le fichier methods.py\n",
    "\n",
    "Leurs formulations diffèrent sur deux points mineurs :\n",
    "- l'une optimise en $\\alpha_i$, l'autre en $\\alpha_i y_i$\n",
    "- les contraintes d'inégalité sont encapsulées dans une classe LinearConstraints de scipy pour l'une des classes.\n",
    "\n",
    "A noter que l'une des classes a été testée vs le classifieur scikit dans le HW2 (Deporte), avec des résultats comparables voire identiques modulo les arrondis numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# ALGO SVC LILIAN\n",
    "#----------------------------------------\n",
    "\n",
    "class KernelSVCLilian():\n",
    "    \n",
    "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None # support vectors\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "       \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "       #### You might define here any variable needed for the rest of the code\n",
    "        N = len(y)\n",
    "        K = self.kernel(X, X)\n",
    "\n",
    "        # Lagrange dual problem\n",
    "        def loss(alpha):\n",
    "            return 0.5*np.dot(alpha*y, np.dot(K, alpha*y)) - np.sum(alpha) #'''--------------dual loss ------------------ '''\n",
    "\n",
    "        # Partial derivate of Ld on alpha\n",
    "        def grad_loss(alpha):\n",
    "            return np.dot(K, alpha*y)*y - np.ones_like(alpha) # '''----------------partial derivative of the dual loss wrt alpha -----------------'''\n",
    "\n",
    "\n",
    "        # Constraints on alpha of the shape :\n",
    "        # -  d - C*alpha  = 0\n",
    "        # -  b - A*alpha >= 0\n",
    "\n",
    "        fun_eq = lambda alpha: np.dot(alpha, y)# '''----------------function defining the equality constraint------------------'''        \n",
    "        jac_eq = lambda alpha: y #'''----------------jacobian wrt alpha of the  equality constraint------------------'''\n",
    "        fun_ineq = lambda alpha: self.C - alpha # '''---------------function defining the inequality constraint-------------------'''     \n",
    "        jac_ineq = lambda alpha: -np.eye(N) # '''---------------jacobian wrt alpha of the  inequality constraint-------------------'''\n",
    "        fun_ineq2 = lambda alpha: alpha # '''---------------function defining the inequality constraint-------------------'''     \n",
    "        jac_ineq2 = lambda alpha: np.eye(N) # '''---------------jacobian wrt alpha of the  inequality constraint-------------------'''\n",
    "        \n",
    "        constraints = ({'type': 'eq',  'fun': fun_eq, 'jac': jac_eq},\n",
    "                       {'type': 'ineq', 'fun': fun_ineq, 'jac': jac_ineq},\n",
    "                       {'type': 'ineq', 'fun': fun_ineq2, 'jac': jac_ineq2}\n",
    "                      )\n",
    "\n",
    "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
    "                                   x0=np.ones(N), \n",
    "                                   method='SLSQP', \n",
    "                                   jac=lambda alpha: grad_loss(alpha), \n",
    "                                   constraints=constraints)\n",
    "        self.alpha = optRes.x\n",
    "\n",
    "        ## Assign the required attributes\n",
    "        idx = self.alpha > self.epsilon\n",
    "        \n",
    "        self.support = X[idx]#'''------------------- A matrix with each row corresponding to support vectors ------------------'''\n",
    "        self.support_alpha = self.alpha[idx]\n",
    "        self.support_y = y[idx]\n",
    "        \n",
    "        self.b =  np.mean(self.support_y - self.separating_function(self.support))#''' -----------------offset of the classifier------------------ '''\n",
    "        self.norm_f = np.sqrt(np.dot(self.alpha*y, np.dot(K, self.alpha*y)))# '''------------------------RKHS norm of the function f ------------------------------'''\n",
    "\n",
    "\n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        K_val = self.kernel(self.support, x)\n",
    "        return np.sum((self.support_alpha*self.support_y)[:, np.newaxis]*K_val, axis=0)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        return 2 * (d+self.b> 0) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# ALGO SVC BEN\n",
    "#----------------------------------------\n",
    "\n",
    "class KernelSVCBen():\n",
    "    \n",
    "    def __init__(self, C, kernel, type='non-linear', epsilon = 1e-3):\n",
    "        self.type = type\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None # support vectors\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "       \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #### You might define here any variable needed for the rest of the code\n",
    "        N = len(y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # compute gram matrix, we might need it :-)\n",
    "        self.gram = self.kernel(X,X)\n",
    "        # vector of ones, size N\n",
    "        self.ones = np.ones(N)\n",
    "        # matrix NxN of y_i on diagonal\n",
    "        self.Dy = np.diag(y)\n",
    "\n",
    "        # Lagrange dual problem\n",
    "        def loss(alpha):\n",
    "            objective_function = 1/2 * alpha @ self.gram @ alpha - alpha @ self.y\n",
    "            return  objective_function\n",
    "\n",
    "        # Partial derivate of Ld on alpha\n",
    "        def grad_loss(alpha):\n",
    "            gradient = self.gram @ alpha - self.y\n",
    "            return gradient\n",
    "\n",
    "        # equality constraint\n",
    "        fun_eq = lambda alpha: alpha @ self.ones      \n",
    "        jac_eq = lambda alpha: self.ones\n",
    "        # inequality constraint avec la classe LinearConstraint de scipy\n",
    "        inequality_constraint = LinearConstraint(self.Dy, np.zeros(N), self.C * self.ones)\n",
    "        \n",
    "        constraints = ( [{'type': 'eq', 'fun': fun_eq, 'jac': jac_eq},\n",
    "                        inequality_constraint]\n",
    "                        )\n",
    "\n",
    "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
    "                                   x0=np.ones(N), \n",
    "                                   method='SLSQP', \n",
    "                                   jac=lambda alpha: grad_loss(alpha), \n",
    "                                   constraints=constraints)\n",
    "        self.alpha = optRes.x\n",
    "\n",
    "        ## Assign the required attributes\n",
    "        # list of indices of support vectors in dataset, None if not a support vector\n",
    "        self.indices_support = np.array([ i if (self.epsilon < self.alpha[i]*self.y[i]) and (self.alpha[i]*self.y[i] <= self.C) else None for i in range(N) ])\n",
    "        self.indices_support = self.indices_support[self.indices_support != None].astype(int)\n",
    "        # support vectors (data points on margin)\n",
    "        self.support = self.X[self.indices_support]\n",
    "        # alphas on support vectors\n",
    "        self.alpha_support = self.alpha[self.indices_support]\n",
    "        # compute b by averaging over support vectors\n",
    "        b = self.y - self.gram @ self.alpha\n",
    "        b_sv = b[self.indices_support]\n",
    "        self.b = np.mean(b_sv)\n",
    "        # '''------------------------RKHS norm of the function f ------------------------------'''\n",
    "        self.norm_f = 1/2 * self.alpha @ self.gram @ self.alpha\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        return self.kernel(x, self.support) @ self.alpha_support + self.b\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        return 2 * (d+self.b> 0) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- XPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
